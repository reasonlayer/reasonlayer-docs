---
title: "Safely referring to credentials in skills and chat"
icon: "lock-a"
description: "After adding your credentials, you're going to want to securely let your Openclaw them in your skill files or directly in chat. 
"
---

## In skills

Reference the credential by its environment variable name in your skill instructions. For example:

````markdown
---
name: call-openrouter-api
description: Call the OpenRouter API for LLM completions. Use when the user needs to generate text or get AI responses.
---

# OpenRouter API Skill

Use the `OPENROUTER_API_KEY` environment variable when making requests to OpenRouter. The key is already available—no need to pass it manually.

Example request:
```bash
curl https://openrouter.ai/api/v1/chat/completions \
  -H "Authorization: Bearer $OPENROUTER_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"model": "openai/gpt-4", "messages": [{"role": "user", "content": "Hello"}]}'
```
````

The credential name you set in the Reasonlayer dashboard (e.g. `OPENROUTER_API_KEY`) is the same name your agent sees at runtime.

## In chat

You can also tell your Openclaw about credentials directly in chat. Refer to them as environment variables:

> "Use the `STRIPE_API_KEY` environment variable when making Stripe API calls."

> "The `DATABASE_URL` env var has the connection string—use it for database queries."

Your Openclaw will use the injected value when it runs, without you exposing the actual secret.